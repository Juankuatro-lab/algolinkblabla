import streamlit as st
import pandas as pd
from data_loader import DataLoader
from analyzer import SEOAnalyzer
from visualizer import SEOVisualizer
from config import TOP_N_PAGES_TO_BOOST, TOP_K_SUGGESTIONS_PER_PAGE

# Configuration de la page
st.set_page_config(
    page_title="Optimiseur de Maillage Interne SEO",
    page_icon="üîó",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Styles CSS personnalis√©s
st.markdown("""
<style>
    .main-header {
        font-size: 48px;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 10px;
    }
    .sub-header {
        text-align: center;
        color: #666;
        margin-bottom: 30px;
    }
</style>
""", unsafe_allow_html=True)

# Header
st.markdown('<p class="main-header">üîó Optimiseur de Maillage Interne</p>', unsafe_allow_html=True)
st.markdown('<p class="sub-header">Analyse SEO bas√©e sur Screaming Frog & Google Search Console</p>', unsafe_allow_html=True)

# Initialisation de la session
if 'data_loaded' not in st.session_state:
    st.session_state.data_loaded = False
    st.session_state.loader = DataLoader()
    st.session_state.merged_data = None
    st.session_state.opportunities = None

# Sidebar pour le chargement des fichiers
with st.sidebar:
    st.header("üìÅ Chargement des donn√©es")
    
    st.subheader("1Ô∏è‚É£ Crawl Screaming Frog *")
    sf_file = st.file_uploader(
        "Export CSV/Excel du crawl",
        type=['csv', 'xlsx'],
        key='sf_file',
        help="Fichier contenant: Address, Link Score, Unique Inlinks, Crawl Depth"
    )
    
    st.subheader("2Ô∏è‚É£ Google Search Console")
    gsc_file = st.file_uploader(
        "Export GSC (optionnel)",
        type=['csv', 'xlsx'],
        key='gsc_file',
        help="Donn√©es GSC: Page, Clicks, Impressions, CTR, Position"
    )
    
    st.subheader("3Ô∏è‚É£ Liens Entrants Internes")
    inlinks_file = st.file_uploader(
        "Export des liens internes (optionnel)",
        type=['csv', 'xlsx'],
        key='inlinks_file',
        help="Fichier contenant: Source, Destination, Anchor"
    )
    
    st.markdown("---")
    
    # Bouton de chargement
    if st.button("üöÄ Charger et Analyser", type="primary", use_container_width=True):
        if sf_file is None:
            st.error("‚ö†Ô∏è Le fichier Screaming Frog est obligatoire")
        else:
            with st.spinner("Chargement des donn√©es..."):
                # Charger SF
                st.session_state.loader.load_screaming_frog(sf_file)
                
                # Charger GSC si fourni
                if gsc_file:
                    st.session_state.loader.load_gsc_data(gsc_file)
                
                # Charger Inlinks si fourni
                if inlinks_file:
                    st.session_state.loader.load_inlinks(inlinks_file)
                
                # Fusionner les donn√©es
                st.session_state.merged_data = st.session_state.loader.merge_data()
                
                if st.session_state.merged_data is not None:
                    st.session_state.data_loaded = True
                    st.rerun()
    
    if st.session_state.data_loaded:
        st.success("‚úÖ Donn√©es charg√©es avec succ√®s!")
        
        if st.button("üîÑ R√©initialiser", use_container_width=True):
            st.session_state.data_loaded = False
            st.session_state.merged_data = None
            st.session_state.opportunities = None
            st.rerun()

# Interface principale
if not st.session_state.data_loaded:
    st.info("üëà Commencez par charger vos fichiers dans la barre lat√©rale")
    
    # Instructions
    with st.expander("üìñ Guide d'utilisation"):
        st.markdown("""
        ### Comment utiliser cet outil ?
        
        **1. Pr√©parez vos fichiers:**
        - **Screaming Frog (obligatoire):** Export du crawl contenant au minimum Address, Link Score, Unique Inlinks, Crawl Depth
        - **Google Search Console (optionnel):** Export avec les colonnes Page, Clicks, Impressions, CTR, Position
        - **Liens internes (optionnel):** Export SF des liens avec Source, Destination, Anchor
        
        **2. Chargez les fichiers** via la barre lat√©rale
        
        **3. Analysez les r√©sultats:**
        - Visualisez les statistiques globales
        - Identifiez les pages √† fort potentiel
        - D√©couvrez les opportunit√©s de liens recommand√©es
        - Exportez les recommandations en CSV
        
        **4. Impl√©mentez les liens** sugg√©r√©s pour am√©liorer votre maillage interne
        """)
    
    with st.expander("‚öôÔ∏è Configuration de l'algorithme"):
        st.markdown("""
        ### Algorithme de scoring
        
        **Score de Priorit√© des Pages:**
        - 30% Impressions GSC (potentiel de trafic)
        - 20% Position moyenne (pages proches de la 1√®re page)
        - 30% Link Score invers√© (pages faibles √† booster)
        - 20% Profondeur de crawl (pages trop profondes)
        
        **Score des Opportunit√©s de Liens:**
        - 40% Force de la page source (Link Score √©lev√©)
        - 40% Similarit√© th√©matique (pertinence du lien)
        - 10% P√©nalit√© liens sortants (√©viter surcharge)
        - 10% Besoin de la page cible (peu de liens entrants)
        
        Vous pouvez modifier ces pond√©rations dans `config.py`
        """)

else:
    # Analyse des donn√©es
    analyzer = SEOAnalyzer(
        st.session_state.merged_data,
        st.session_state.loader.inlinks_data
    )
    visualizer = SEOVisualizer()
    
    # Calculer les scores de priorit√© une seule fois
    if 'priority_data' not in st.session_state:
        with st.spinner("Calcul des scores de priorit√©..."):
            st.session_state.priority_data = analyzer.calculate_priority_score()
    
    # Onglets principaux
    tab1, tab2, tab3, tab4 = st.tabs([
        "üìä Vue d'ensemble",
        "üéØ Pages Prioritaires",
        "üîó Opportunit√©s de Liens",
        "üìà Visualisations"
    ])
    
    # TAB 1: Vue d'ensemble
    with tab1:
        st.header("üìä Statistiques Globales")
        
        stats = analyzer.get_statistics()
        st.markdown(visualizer.display_stats_cards(stats), unsafe_allow_html=True)
        
        st.markdown("---")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("üìâ Distribution des Scores de Priorit√©")
            fig_ls = visualizer.plot_priority_distribution(st.session_state.priority_data)
            st.plotly_chart(fig_ls, use_container_width=True)
        
        with col2:
            st.subheader("üéØ Link Score vs Profondeur")
            fig_scatter = visualizer.plot_link_score_vs_depth(st.session_state.priority_data)
            st.plotly_chart(fig_scatter, use_container_width=True)
        
        if st.session_state.loader.gsc_data is not None:
            st.subheader("üèÜ Top Pages GSC")
            fig_gsc = visualizer.plot_gsc_performance(st.session_state.merged_data)
            st.plotly_chart(fig_gsc, use_container_width=True)
    
    # TAB 2: Pages Prioritaires
    with tab2:
        st.header("üéØ Pages √† Prioriser pour le Maillage")
        
        with st.spinner("Calcul des scores de priorit√©..."):
            df_priority = analyzer.calculate_priority_score()
        
        st.markdown(f"""
        Les **{TOP_N_PAGES_TO_BOOST} pages** ci-dessous ont le plus fort potentiel d'am√©lioration.
        Elles combinent un bon potentiel GSC avec un Link Score faible.
        """)
        
        # Filtres
        col1, col2, col3 = st.columns(3)
        with col1:
            min_impressions = st.number_input("Impressions min.", 0, int(df_priority['Impressions'].max()), 0)
        with col2:
            max_position = st.number_input("Position max.", 1, 100, 100)
        with col3:
            show_potential_only = st.checkbox("Uniquement pages √† fort potentiel", value=False)
        
        # Appliquer les filtres
        filtered = df_priority[
            (df_priority['Impressions'] >= min_impressions) &
            (df_priority['Position'] <= max_position)
        ]
        
        if show_potential_only:
            filtered = filtered[filtered['Has_Potential'] == True]
        
        # Affichage
        display_cols = [
            'Address', 'Priority_Score', 'Link Score', 'Unique Inlinks',
            'Crawl Depth', 'Impressions', 'Clicks', 'Position', 'Has_Potential'
        ]
        
        st.dataframe(
            filtered[display_cols].head(100),
            use_container_width=True,
            height=400
        )
        
        # Export
        csv_priority = filtered[display_cols].to_csv(index=False).encode('utf-8')
        st.download_button(
            label="üì• T√©l√©charger les pages prioritaires (CSV)",
            data=csv_priority,
            file_name="pages_prioritaires_seo.csv",
            mime="text/csv"
        )
    
    # TAB 3: Opportunit√©s de Liens
    with tab3:
        st.header("üîó Recommandations de Liens Internes")
        
        if st.session_state.opportunities is None:
            with st.spinner("G√©n√©ration des opportunit√©s de liens... Cela peut prendre quelques minutes."):
                st.session_state.opportunities = analyzer.generate_link_opportunities()
        
        opportunities = st.session_state.opportunities
        
        if len(opportunities) == 0:
            st.warning("‚ö†Ô∏è Aucune opportunit√© de lien trouv√©e avec les crit√®res actuels.")
            st.info("Essayez de r√©duire le seuil de similarit√© dans config.py ou v√©rifiez vos donn√©es.")
        else:
            st.success(f"‚úÖ {len(opportunities)} opportunit√©s de liens identifi√©es!")
            
            st.markdown(f"""
            Chaque page cible re√ßoit jusqu'√† **{TOP_K_SUGGESTIONS_PER_PAGE} suggestions** de liens entrants.
            Les recommandations sont tri√©es par score d'opportunit√© (pertinence √ó impact potentiel).
            """)
            
            # Filtres
            col1, col2 = st.columns(2)
            with col1:
                min_similarity = st.slider(
                    "Similarit√© minimale",
                    0.0, 1.0, 0.1, 0.05,
                    help="Filtrer les liens par pertinence th√©matique"
                )
            with col2:
                min_source_ls = st.number_input(
                    "Link Score source min.",
                    0, 100, 0,
                    help="Filtrer par force de la page source"
                )
            
            # Appliquer les filtres
            filtered_opp = opportunities[
                (opportunities['Similarity'] >= min_similarity) &
                (opportunities['Source_LinkScore'] >= min_source_ls)
            ]
            
            st.metric("Opportunit√©s filtr√©es", len(filtered_opp))
            
            # Affichage du tableau
            display_opp_cols = [
                'Source', 'Target', 'Opportunity_Score', 'Similarity',
                'Source_LinkScore', 'Target_LinkScore', 'Source_Outlinks',
                'Target_Inlinks', 'Target_Impressions', 'Target_Position'
            ]
            
            st.dataframe(
                filtered_opp[display_opp_cols],
                use_container_width=True,
                height=500
            )
            
            # Section d√©tails pour une opportunit√©
            st.markdown("---")
            st.subheader("üîç D√©tails d'une Opportunit√©")
            
            if len(filtered_opp) > 0:
                selected_idx = st.selectbox(
                    "S√©lectionnez une opportunit√©",
                    range(len(filtered_opp)),
                    format_func=lambda x: f"#{x+1}: {filtered_opp.iloc[x]['Source'][:50]}... ‚Üí {filtered_opp.iloc[x]['Target'][:50]}..."
                )
                
                selected = filtered_opp.iloc[selected_idx]
                
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown("**üì§ Page Source**")
                    st.write(f"URL: `{selected['Source']}`")
                    st.write(f"Link Score: **{selected['Source_LinkScore']:.1f}**")
                    st.write(f"Liens sortants actuels: {selected['Source_Outlinks']}")
                
                with col2:
                    st.markdown("**üì• Page Cible**")
                    st.write(f"URL: `{selected['Target']}`")
                    st.write(f"Link Score: **{selected['Target_LinkScore']:.1f}**")
                    st.write(f"Liens entrants: {selected['Target_Inlinks']}")
                    st.write(f"Impressions GSC: {selected['Target_Impressions']:.0f}")
                    st.write(f"Position: {selected['Target_Position']:.1f}")
                
                st.markdown("**üìä Scores**")
                score_col1, score_col2, score_col3 = st.columns(3)
                score_col1.metric("Score Opportunit√©", f"{selected['Opportunity_Score']:.3f}")
                score_col2.metric("Similarit√©", f"{selected['Similarity']:.3f}")
                score_col3.metric("Priorit√© Cible", f"{selected['Target_Priority_Score']:.3f}")
            
            # Export
            csv_opportunities = filtered_opp.to_csv(index=False).encode('utf-8')
            st.download_button(
                label="üì• T√©l√©charger les recommandations (CSV)",
                data=csv_opportunities,
                file_name="opportunites_liens_seo.csv",
                mime="text/csv",
                type="primary"
            )
    
    # TAB 4: Visualisations
    with tab4:
        st.header("üìà Visualisations Avanc√©es")
        
        if st.session_state.opportunities is not None and len(st.session_state.opportunities) > 0:
            st.subheader("üï∏Ô∏è Graphe de Maillage Recommand√©")
            
            max_links_graph = st.slider(
                "Nombre de liens √† afficher",
                10, 100, 50, 10,
                help="Limiter pour am√©liorer la lisibilit√©"
            )
            
            with st.spinner("G√©n√©ration du graphe..."):
                fig_network = visualizer.plot_network_graph(
                    st.session_state.opportunities,
                    max_links=max_links_graph
                )
                st.plotly_chart(fig_network, use_container_width=True)
            
            st.info("üí° Les n≈ìuds repr√©sentent les pages, les fl√®ches les liens recommand√©s. La taille et la couleur indiquent le nombre de connexions.")
        else:
            st.warning("‚ö†Ô∏è G√©n√©rez d'abord les opportunit√©s de liens dans l'onglet pr√©c√©dent.")

# Footer
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #666; padding: 20px;'>
    <p>üîó Optimiseur de Maillage Interne SEO | D√©velopp√© avec Streamlit</p>
    <p>Donn√©es: Screaming Frog + Google Search Console</p>
</div>
""", unsafe_allow_html=True)
